{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "from model_def import get_model\n",
    "\n",
    "HEIGHT = 32\n",
    "WIDTH  = 32\n",
    "DEPTH  = 3\n",
    "NUM_CLASSES = 10\n",
    "NUM_TRAIN_IMAGES = 40000\n",
    "NUM_VALID_IMAGES = 10000\n",
    "NUM_TEST_IMAGES  = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocess_fn(image):\n",
    "\n",
    "    # Resize the image to add four extra pixels on each side.\n",
    "    image = tf.image.resize_image_with_crop_or_pad(image, HEIGHT + 8, WIDTH + 8)\n",
    "\n",
    "    # Randomly crop a [HEIGHT, WIDTH] section of the image.\n",
    "    image = tf.random_crop(image, [HEIGHT, WIDTH, DEPTH])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(filenames, batch_size):\n",
    "    \"\"\"Read the images and labels from 'filenames'.\"\"\"\n",
    "    # Repeat infinitely.\n",
    "    dataset = tf.data.TFRecordDataset(filenames).repeat()\n",
    "\n",
    "    # Parse records.\n",
    "    dataset = dataset.map(single_example_parser, num_parallel_calls=1)\n",
    "\n",
    "    # Batch it up.\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    image_batch, label_batch = iterator.get_next()\n",
    "    return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_example_parser(serialized_example):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    # Dimensions of the images in the CIFAR-10 dataset.\n",
    "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "    # input format.\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    image.set_shape([DEPTH * HEIGHT * WIDTH])\n",
    "\n",
    "    # Reshape from [depth * height * width] to [depth, height, width].\n",
    "    image = tf.cast(\n",
    "        tf.transpose(tf.reshape(image, [DEPTH, HEIGHT, WIDTH]), [1, 2, 0]),\n",
    "        tf.float32)\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    \n",
    "    image = train_preprocess_fn(image)\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "epochs = 15\n",
    "lr = 0.01\n",
    "batch_size = 128\n",
    "momentum = 0.9\n",
    "weight_decay = 2e-4\n",
    "optimizer = 'sgd'\n",
    "\n",
    "# Data directories and other options\n",
    "gpu_count = 1\n",
    "checkpoint_dir = 'ckpt_dir'\n",
    "train_dir = '../data/train'\n",
    "validation_dir = '../data/validation'\n",
    "eval_dir = '../data/eval'\n",
    "\n",
    "train_dataset = make_batch(train_dir+'/train.tfrecords',  batch_size)\n",
    "val_dataset = make_batch(validation_dir+'/validation.tfrecords', batch_size)\n",
    "eval_dataset = make_batch(eval_dir+'/eval.tfrecords', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(lr, weight_decay, optimizer, momentum)\n",
    "opt = SGD(lr=lr, decay=weight_decay, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=SGD(lr=lr, decay=weight_decay, momentum=momentum),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model\n",
    "history = model.fit(x=train_dataset[0], y=train_dataset[1],\n",
    "                    steps_per_epoch=NUM_TRAIN_IMAGES // batch_size,\n",
    "                    validation_data=val_dataset,\n",
    "                    validation_steps=NUM_VALID_IMAGES // batch_size,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[ModelCheckpoint(checkpoint_dir + '/checkpoint-{epoch}.h5')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "score = model.evaluate(eval_dataset[0],\n",
    "                       eval_dataset[1],\n",
    "                       steps=NUM_TEST_IMAGES // batch_size,\n",
    "                       verbose=0)\n",
    "print('Test loss    :', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
